{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>step</th>\n",
       "      <th>reward</th>\n",
       "      <th>info</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>obs_0</th>\n",
       "      <th>obs_1</th>\n",
       "      <th>obs_2</th>\n",
       "      <th>obs_3</th>\n",
       "      <th>obs_4</th>\n",
       "      <th>...</th>\n",
       "      <th>obs_309</th>\n",
       "      <th>obs_310</th>\n",
       "      <th>obs_311</th>\n",
       "      <th>obs_312</th>\n",
       "      <th>obs_313</th>\n",
       "      <th>obs_314</th>\n",
       "      <th>obs_315</th>\n",
       "      <th>obs_316</th>\n",
       "      <th>obs_317</th>\n",
       "      <th>obs_318</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.389655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.679650e+09</td>\n",
       "      <td>0.013682</td>\n",
       "      <td>0.013316</td>\n",
       "      <td>-0.021371</td>\n",
       "      <td>-0.029317</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009389</td>\n",
       "      <td>-0.535267</td>\n",
       "      <td>-0.001717</td>\n",
       "      <td>0.844681</td>\n",
       "      <td>0.844631</td>\n",
       "      <td>-0.012196</td>\n",
       "      <td>0.535210</td>\n",
       "      <td>0.009383</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.007979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.513281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.679650e+09</td>\n",
       "      <td>0.043853</td>\n",
       "      <td>0.042083</td>\n",
       "      <td>-0.056912</td>\n",
       "      <td>-0.077301</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025483</td>\n",
       "      <td>-0.528323</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>0.849039</td>\n",
       "      <td>0.848661</td>\n",
       "      <td>-0.031585</td>\n",
       "      <td>0.527993</td>\n",
       "      <td>0.025468</td>\n",
       "      <td>0.999498</td>\n",
       "      <td>0.018856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.559966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.679650e+09</td>\n",
       "      <td>0.084186</td>\n",
       "      <td>0.080007</td>\n",
       "      <td>-0.089216</td>\n",
       "      <td>-0.121493</td>\n",
       "      <td>-0.008056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031378</td>\n",
       "      <td>-0.530603</td>\n",
       "      <td>-0.002908</td>\n",
       "      <td>0.847615</td>\n",
       "      <td>0.847040</td>\n",
       "      <td>-0.038816</td>\n",
       "      <td>0.530110</td>\n",
       "      <td>0.031360</td>\n",
       "      <td>0.999242</td>\n",
       "      <td>0.023059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.557379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.679650e+09</td>\n",
       "      <td>0.130438</td>\n",
       "      <td>0.123797</td>\n",
       "      <td>-0.110976</td>\n",
       "      <td>-0.150377</td>\n",
       "      <td>-0.028199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021509</td>\n",
       "      <td>-0.546160</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>0.837681</td>\n",
       "      <td>0.837405</td>\n",
       "      <td>-0.026035</td>\n",
       "      <td>0.545963</td>\n",
       "      <td>0.021497</td>\n",
       "      <td>0.999661</td>\n",
       "      <td>0.014698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.514907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.679650e+09</td>\n",
       "      <td>0.179715</td>\n",
       "      <td>0.170944</td>\n",
       "      <td>-0.118389</td>\n",
       "      <td>-0.157974</td>\n",
       "      <td>-0.052214</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005936</td>\n",
       "      <td>-0.575679</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>0.817660</td>\n",
       "      <td>0.817655</td>\n",
       "      <td>0.010918</td>\n",
       "      <td>0.575606</td>\n",
       "      <td>-0.005928</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>-0.010545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>9.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>1.643387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.679650e+09</td>\n",
       "      <td>0.016023</td>\n",
       "      <td>-0.021945</td>\n",
       "      <td>-0.223133</td>\n",
       "      <td>-0.128909</td>\n",
       "      <td>-0.091112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092495</td>\n",
       "      <td>-0.322932</td>\n",
       "      <td>-0.032672</td>\n",
       "      <td>0.945858</td>\n",
       "      <td>0.941897</td>\n",
       "      <td>-0.108712</td>\n",
       "      <td>0.317824</td>\n",
       "      <td>0.092442</td>\n",
       "      <td>0.993536</td>\n",
       "      <td>0.065880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>9.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>1.642209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.679650e+09</td>\n",
       "      <td>0.011088</td>\n",
       "      <td>-0.025304</td>\n",
       "      <td>-0.222518</td>\n",
       "      <td>-0.133515</td>\n",
       "      <td>-0.092572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099743</td>\n",
       "      <td>-0.319556</td>\n",
       "      <td>-0.033837</td>\n",
       "      <td>0.946963</td>\n",
       "      <td>0.942309</td>\n",
       "      <td>-0.116484</td>\n",
       "      <td>0.313823</td>\n",
       "      <td>0.099688</td>\n",
       "      <td>0.992616</td>\n",
       "      <td>0.069108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>9.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>1.642716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.679650e+09</td>\n",
       "      <td>0.007984</td>\n",
       "      <td>-0.027461</td>\n",
       "      <td>-0.222570</td>\n",
       "      <td>-0.145634</td>\n",
       "      <td>-0.094361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112104</td>\n",
       "      <td>-0.318070</td>\n",
       "      <td>-0.036716</td>\n",
       "      <td>0.947356</td>\n",
       "      <td>0.941423</td>\n",
       "      <td>-0.130324</td>\n",
       "      <td>0.311027</td>\n",
       "      <td>0.112044</td>\n",
       "      <td>0.990791</td>\n",
       "      <td>0.076017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>9.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>1.634751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.679650e+09</td>\n",
       "      <td>0.004195</td>\n",
       "      <td>-0.029033</td>\n",
       "      <td>-0.222018</td>\n",
       "      <td>-0.171272</td>\n",
       "      <td>-0.096102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133622</td>\n",
       "      <td>-0.317409</td>\n",
       "      <td>-0.042347</td>\n",
       "      <td>0.947343</td>\n",
       "      <td>0.938837</td>\n",
       "      <td>-0.154726</td>\n",
       "      <td>0.307643</td>\n",
       "      <td>0.133551</td>\n",
       "      <td>0.987049</td>\n",
       "      <td>0.088868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>9.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>1.639940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.679650e+09</td>\n",
       "      <td>-0.001276</td>\n",
       "      <td>-0.030896</td>\n",
       "      <td>-0.217826</td>\n",
       "      <td>-0.178758</td>\n",
       "      <td>-0.096755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151027</td>\n",
       "      <td>-0.319419</td>\n",
       "      <td>-0.045754</td>\n",
       "      <td>0.946508</td>\n",
       "      <td>0.935514</td>\n",
       "      <td>-0.174333</td>\n",
       "      <td>0.307282</td>\n",
       "      <td>0.150948</td>\n",
       "      <td>0.983623</td>\n",
       "      <td>0.098489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 324 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      episode   step    reward  info     timestamp     obs_0     obs_1  \\\n",
       "0         0.0    0.0 -1.389655   0.0  1.679650e+09  0.013682  0.013316   \n",
       "1         0.0    1.0 -1.513281   0.0  1.679650e+09  0.043853  0.042083   \n",
       "2         0.0    2.0 -1.559966   0.0  1.679650e+09  0.084186  0.080007   \n",
       "3         0.0    3.0 -1.557379   0.0  1.679650e+09  0.130438  0.123797   \n",
       "4         0.0    4.0 -1.514907   0.0  1.679650e+09  0.179715  0.170944   \n",
       "...       ...    ...       ...   ...           ...       ...       ...   \n",
       "1995      9.0  195.0  1.643387   0.0  1.679650e+09  0.016023 -0.021945   \n",
       "1996      9.0  196.0  1.642209   0.0  1.679650e+09  0.011088 -0.025304   \n",
       "1997      9.0  197.0  1.642716   0.0  1.679650e+09  0.007984 -0.027461   \n",
       "1998      9.0  198.0  1.634751   0.0  1.679650e+09  0.004195 -0.029033   \n",
       "1999      9.0  199.0  1.639940   0.0  1.679650e+09 -0.001276 -0.030896   \n",
       "\n",
       "         obs_2     obs_3     obs_4  ...   obs_309   obs_310   obs_311  \\\n",
       "0    -0.021371 -0.029317  0.001221  ...  0.009389 -0.535267 -0.001717   \n",
       "1    -0.056912 -0.077301  0.003332  ...  0.025483 -0.528323 -0.002555   \n",
       "2    -0.089216 -0.121493 -0.008056  ...  0.031378 -0.530603 -0.002908   \n",
       "3    -0.110976 -0.150377 -0.028199  ...  0.021509 -0.546160 -0.000571   \n",
       "4    -0.118389 -0.157974 -0.052214  ... -0.005936 -0.575679  0.005210   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1995 -0.223133 -0.128909 -0.091112  ...  0.092495 -0.322932 -0.032672   \n",
       "1996 -0.222518 -0.133515 -0.092572  ...  0.099743 -0.319556 -0.033837   \n",
       "1997 -0.222570 -0.145634 -0.094361  ...  0.112104 -0.318070 -0.036716   \n",
       "1998 -0.222018 -0.171272 -0.096102  ...  0.133622 -0.317409 -0.042347   \n",
       "1999 -0.217826 -0.178758 -0.096755  ...  0.151027 -0.319419 -0.045754   \n",
       "\n",
       "       obs_312   obs_313   obs_314   obs_315   obs_316   obs_317   obs_318  \n",
       "0     0.844681  0.844631 -0.012196  0.535210  0.009383  0.999924  0.007979  \n",
       "1     0.849039  0.848661 -0.031585  0.527993  0.025468  0.999498  0.018856  \n",
       "2     0.847615  0.847040 -0.038816  0.530110  0.031360  0.999242  0.023059  \n",
       "3     0.837681  0.837405 -0.026035  0.545963  0.021497  0.999661  0.014698  \n",
       "4     0.817660  0.817655  0.010918  0.575606 -0.005928  0.999927 -0.010545  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1995  0.945858  0.941897 -0.108712  0.317824  0.092442  0.993536  0.065880  \n",
       "1996  0.946963  0.942309 -0.116484  0.313823  0.099688  0.992616  0.069108  \n",
       "1997  0.947356  0.941423 -0.130324  0.311027  0.112044  0.990791  0.076017  \n",
       "1998  0.947343  0.938837 -0.154726  0.307643  0.133551  0.987049  0.088868  \n",
       "1999  0.946508  0.935514 -0.174333  0.307282  0.150948  0.983623  0.098489  \n",
       "\n",
       "[2000 rows x 324 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"result.csv\", delimiter=\",\")\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build the network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/develop-your-first-neural-network-with-pytorch-step-by-step/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([df.iloc[:,4:46],df.iloc[:,46:]],axis=1,ignore_index=True)\n",
    "\n",
    "y = df.iloc[:,45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X.values.astype(np.float32))\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 320])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1),\n",
    "    nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PimaClassifier(\n",
      "  (hidden1): Linear(in_features=320, out_features=160, bias=True)\n",
      "  (act1): ReLU()\n",
      "  (hidden2): Linear(in_features=160, out_features=80, bias=True)\n",
      "  (act2): ReLU()\n",
      "  (output): Linear(in_features=80, out_features=16, bias=True)\n",
      "  (act_output): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(320, 160)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(160, 80)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.output = nn.Linear(80, 16)\n",
    "        self.act_output =  nn.Linear(16, 1)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    " \n",
    "model = PimaClassifier()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5550e-18],\n",
       "        [-2.4689e-17],\n",
       "        [-9.8585e-17],\n",
       "        [-2.3664e-16],\n",
       "        [-1.2744e-06],\n",
       "        [-9.1876e-06],\n",
       "        [-1.4657e-05],\n",
       "        [-1.7064e-05],\n",
       "        [ 3.7224e-03],\n",
       "        [ 1.5565e-02]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, latest loss 7748.1298828125\n",
      "Finished epoch 1, latest loss 0.41201943159103394\n",
      "Finished epoch 2, latest loss 0.01066088117659092\n",
      "Finished epoch 3, latest loss 1.9202991724014282\n",
      "Finished epoch 4, latest loss 0.8531777262687683\n",
      "Finished epoch 5, latest loss 0.6139273643493652\n",
      "Finished epoch 6, latest loss 0.08486442267894745\n",
      "Finished epoch 7, latest loss 0.48295658826828003\n",
      "Finished epoch 8, latest loss 0.3270663321018219\n",
      "Finished epoch 9, latest loss 0.34234756231307983\n",
      "Finished epoch 10, latest loss 162.12570190429688\n",
      "Finished epoch 11, latest loss 1344.9486083984375\n",
      "Finished epoch 12, latest loss 39550.734375\n",
      "Finished epoch 13, latest loss 8.149935722351074\n",
      "Finished epoch 14, latest loss 0.4979695677757263\n",
      "Finished epoch 15, latest loss 0.22413849830627441\n",
      "Finished epoch 16, latest loss 16084699.0\n",
      "Finished epoch 17, latest loss 47.94384765625\n",
      "Finished epoch 18, latest loss 0.2372269332408905\n",
      "Finished epoch 19, latest loss 176.19418334960938\n",
      "Finished epoch 20, latest loss 50545.6171875\n",
      "Finished epoch 21, latest loss 5.182731628417969\n",
      "Finished epoch 22, latest loss 0.08488170802593231\n",
      "Finished epoch 23, latest loss 4.1069512367248535\n",
      "Finished epoch 24, latest loss 111.28282165527344\n",
      "Finished epoch 25, latest loss 18.506349563598633\n",
      "Finished epoch 26, latest loss 1.1167227029800415\n",
      "Finished epoch 27, latest loss 17.886619567871094\n",
      "Finished epoch 28, latest loss 0.03995002061128616\n",
      "Finished epoch 29, latest loss 72.65180969238281\n",
      "Finished epoch 30, latest loss 301.98760986328125\n",
      "Finished epoch 31, latest loss 3.7985267639160156\n",
      "Finished epoch 32, latest loss 0.1674949824810028\n",
      "Finished epoch 33, latest loss 40.036338806152344\n",
      "Finished epoch 34, latest loss 10190.5654296875\n",
      "Finished epoch 35, latest loss 0.03267165645956993\n",
      "Finished epoch 36, latest loss 15.304550170898438\n",
      "Finished epoch 37, latest loss 3705.563232421875\n",
      "Finished epoch 38, latest loss 5.8424763679504395\n",
      "Finished epoch 39, latest loss 4.322818756103516\n",
      "Finished epoch 40, latest loss 0.14450469613075256\n",
      "Finished epoch 41, latest loss 0.0051935454830527306\n",
      "Finished epoch 42, latest loss 7.555381774902344\n",
      "Finished epoch 43, latest loss 2807629.25\n",
      "Finished epoch 44, latest loss 2.2582595348358154\n",
      "Finished epoch 45, latest loss 0.00799288135021925\n",
      "Finished epoch 46, latest loss 0.02307409979403019\n",
      "Finished epoch 47, latest loss 4.365592002868652\n",
      "Finished epoch 48, latest loss 0.7412863373756409\n",
      "Finished epoch 49, latest loss 53.08074188232422\n",
      "Finished epoch 50, latest loss 1321.170166015625\n",
      "Finished epoch 51, latest loss 0.04377727955579758\n",
      "Finished epoch 52, latest loss 1.1389102935791016\n",
      "Finished epoch 53, latest loss 0.11148928105831146\n",
      "Finished epoch 54, latest loss 5.9367241859436035\n",
      "Finished epoch 55, latest loss 287487.9375\n",
      "Finished epoch 56, latest loss 0.029894601553678513\n",
      "Finished epoch 57, latest loss 1.6571988453506492e-05\n",
      "Finished epoch 58, latest loss 3.125593900680542\n",
      "Finished epoch 59, latest loss 3.407857894897461\n",
      "Finished epoch 60, latest loss 681.9928588867188\n",
      "Finished epoch 61, latest loss 0.07087240368127823\n",
      "Finished epoch 62, latest loss 0.4074166715145111\n",
      "Finished epoch 63, latest loss 0.039181772619485855\n",
      "Finished epoch 64, latest loss 0.03167293593287468\n",
      "Finished epoch 65, latest loss 0.0009181210771203041\n",
      "Finished epoch 66, latest loss 0.0006219317438080907\n",
      "Finished epoch 67, latest loss 9.471586227416992\n",
      "Finished epoch 68, latest loss 0.22399237751960754\n",
      "Finished epoch 69, latest loss 0.12353049218654633\n",
      "Finished epoch 70, latest loss 0.0351870134472847\n",
      "Finished epoch 71, latest loss 0.017643408849835396\n",
      "Finished epoch 72, latest loss 0.0505797453224659\n",
      "Finished epoch 73, latest loss 0.038131263107061386\n",
      "Finished epoch 74, latest loss 0.02869664505124092\n",
      "Finished epoch 75, latest loss 0.03466472774744034\n",
      "Finished epoch 76, latest loss 0.14287634193897247\n",
      "Finished epoch 77, latest loss 3189.117919921875\n",
      "Finished epoch 78, latest loss 0.09071218967437744\n",
      "Finished epoch 79, latest loss 0.04773976653814316\n",
      "Finished epoch 80, latest loss 0.35673609375953674\n",
      "Finished epoch 81, latest loss 1651.519287109375\n",
      "Finished epoch 82, latest loss 0.02621648833155632\n",
      "Finished epoch 83, latest loss 0.21092841029167175\n",
      "Finished epoch 84, latest loss 0.14287060499191284\n",
      "Finished epoch 85, latest loss 1496.070068359375\n",
      "Finished epoch 86, latest loss 0.00030257212347351015\n",
      "Finished epoch 87, latest loss 0.2174806296825409\n",
      "Finished epoch 88, latest loss 0.020474761724472046\n",
      "Finished epoch 89, latest loss 0.08872053772211075\n",
      "Finished epoch 90, latest loss 103563.6796875\n",
      "Finished epoch 91, latest loss 0.006978273391723633\n",
      "Finished epoch 92, latest loss 0.004838846158236265\n",
      "Finished epoch 93, latest loss 0.1629842072725296\n",
      "Finished epoch 94, latest loss 1.4229643056751229e-05\n",
      "Finished epoch 95, latest loss 29.665302276611328\n",
      "Finished epoch 96, latest loss 0.17577563226222992\n",
      "Finished epoch 97, latest loss 0.0007642906275577843\n",
      "Finished epoch 98, latest loss 0.013170468620955944\n",
      "Finished epoch 99, latest loss 6265.71484375\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MSELoss()  # binary cross entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 65.57 RMSE\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy (no_grad is optional)\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    " \n",
    "trainScore = math.sqrt(mean_squared_error(y_pred,y))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
